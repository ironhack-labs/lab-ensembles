{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9975797-fbde-4f96-8aac-85a4f950c421",
   "metadata": {},
   "source": [
    "# Challenge 1\n",
    "\n",
    "The heart disease dataset is a classic dataset that contains various health metrics (age, sex, chest pain type, blood pressure, cholesterol, etc.) related to diagnosing heart disease (binary classification: presence or absence of heart disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cf591d-8a5b-499e-8715-1ad140867934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for data manipulation and model building\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset (change the path if needed)\n",
    "df = pd.read_csv('../data/heart.csv')\n",
    "\n",
    "# Check the shape of the dataset (optional)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdacba24-2347-4556-9cf2-2b872ccbede3",
   "metadata": {},
   "source": [
    "### Dataset Shape\n",
    "\n",
    "After loading the dataset, we checked its shape using `df.shape`. The output indicates that the dataset contains **303 rows** and **14 columns**. \n",
    "\n",
    "This means there are 303 instances (or samples) and 14 features (including the target variable) in the dataset. We will use these features to build our model and predict the presence or absence of heart disease.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb5ea1c-a4e5-4419-bae8-661fe2d82711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset to understand its structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267d8b98-8d18-41fa-9c3d-4b0a18a8aaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "# This will help ensure the dataset doesn't have any missing values before we start training the models\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34586925-fc89-43e1-983b-a93d077bbd4d",
   "metadata": {},
   "source": [
    "### Checking for Missing Values\n",
    "\n",
    "After displaying the initial rows of the dataset, we perform a check for missing values. This step is important to ensure that there are no missing values in the dataset before we proceed with training the models. The output shows that there are no missing values in any of the columns, which means we can move forward without any data cleaning regarding missing values.\n",
    "\n",
    "The check for missing values returned zeros across all columns, indicating no missing entries:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ebc45-d873-4c37-b1e4-ce2b0ebc08f2",
   "metadata": {},
   "source": [
    "We are going to try to predict the presence of heart disease suing this features, starting with a classical baseline method and trying to improve on that result with a series of ensembled approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ad7e40-87f3-4b93-bef9-a9ddb5881ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and target variable\n",
    "# 'X' contains all columns except for 'target', which are the features we will use to predict heart disease\n",
    "# 'y' contains the 'target' column, which is the label indicating presence (1) or absence (0) of heart disease\n",
    "X = df.drop(columns=\"target\")  # Drop the 'target' column to get the feature matrix\n",
    "y = df[\"target\"]  # Extract the 'target' column as the target variable (labels)\n",
    "\n",
    "# Train-test split: This is used to separate the dataset into training and testing sets\n",
    "# The model will be trained on the training set and evaluated on the test set to check its generalization performance\n",
    "# test_size=0.25 means 25% of the data will be used as the test set, and 75% will be used for training\n",
    "# random_state=0 ensures that the split is reproducible, so you'll get the same split every time you run this code\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Feature scaling: Scaling the features is necessary for models that rely on distance (like SVMs or logistic regression)\n",
    "# For decision trees, scaling is not essential, but it's good practice to scale the features when using models that might require it\n",
    "# StandardScaler standardizes the features by removing the mean and scaling them to unit variance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data (calculate mean and standard deviation), and transform it to apply scaling\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply the same transformation to the test data, using the parameters learned from the training set (so the test data is scaled in the same way)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0153586-1242-43a0-bb61-78b1234434a6",
   "metadata": {},
   "source": [
    "# Baseline model : decision Tree\n",
    "\n",
    "We'll train a decision tree as our baseline model and evaluate it using accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d39376f1-b4ca-44c0-8364-d11b9a7605f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Training Accuracy: 1.0000\n",
      "Baseline Test Accuracy: 0.7895\n",
      "Baseline Training MSE: 0.0000\n",
      "Baseline Test MSE: 0.2105\n",
      "Pruned Training Accuracy: 0.8546\n",
      "Pruned Test Accuracy: 0.7632\n",
      "Pruned Training MSE: 0.1454\n",
      "Pruned Test MSE: 0.2368\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for model creation and evaluation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# Create and initialize a Decision Tree Classifier model\n",
    "# The 'random_state' ensures reproducibility of results by controlling the randomness\n",
    "dt_classifier = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Train the Decision Tree Classifier using the scaled training data\n",
    "# 'X_train_scaled' contains the features of the training set,\n",
    "# 'y_train' contains the target labels (heart disease presence)\n",
    "dt_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = dt_classifier.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = dt_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Print the evaluation metrics for the baseline decision tree\n",
    "print(f\"Baseline Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Baseline Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Baseline Training MSE: {train_mse:.4f}\")\n",
    "print(f\"Baseline Test MSE: {test_mse:.4f}\")\n",
    "\n",
    "# Now let's add a pruned decision tree to reduce overfitting\n",
    "\n",
    "# Create and initialize a pruned Decision Tree Classifier model\n",
    "# Limiting the depth of the tree to 3 to prevent overfitting\n",
    "dt_classifier_pruned = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "\n",
    "# Train the pruned Decision Tree Classifier\n",
    "dt_classifier_pruned.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the training set for the pruned tree\n",
    "y_train_pred_pruned = dt_classifier_pruned.predict(X_train_scaled)\n",
    "\n",
    "# Make predictions on the test set for the pruned tree\n",
    "y_test_pred_pruned = dt_classifier_pruned.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the performance of the pruned model\n",
    "train_accuracy_pruned = accuracy_score(y_train, y_train_pred_pruned)\n",
    "test_accuracy_pruned = accuracy_score(y_test, y_test_pred_pruned)\n",
    "train_mse_pruned = mean_squared_error(y_train, y_train_pred_pruned)\n",
    "test_mse_pruned = mean_squared_error(y_test, y_test_pred_pruned)\n",
    "\n",
    "# Print the evaluation metrics for the pruned decision tree\n",
    "print(f\"Pruned Training Accuracy: {train_accuracy_pruned:.4f}\")\n",
    "print(f\"Pruned Test Accuracy: {test_accuracy_pruned:.4f}\")\n",
    "print(f\"Pruned Training MSE: {train_mse_pruned:.4f}\")\n",
    "print(f\"Pruned Test MSE: {test_mse_pruned:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9502aa2-06b0-4cf2-bc6b-cb91390ff1a8",
   "metadata": {},
   "source": [
    "We can see that this model is overfitting. This is expected, decision trees, especially deep ones  are notorious agressive at exploiting the data available. But that also makes them highly variant: a small change on the tree/data makes for potentially large changes in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888355b-6988-43d1-812a-54441dd57df6",
   "metadata": {},
   "source": [
    "### Understanding Overfitting in Our Decision Tree Model\n",
    "\n",
    "As seen in the previous evaluation, the decision tree has achieved **perfect accuracy on the training set (1.0000)** but only **78.95% accuracy on the test set**. This discrepancy is a classic indicator of **overfitting**, which was expected due to the complexity of the model.\n",
    "\n",
    "- **Overfitting** happens when a model learns not only the general patterns in the data but also the noise or random fluctuations that may be present in the training set. This makes the model very specific to the training data, and it fails to generalize well to unseen data.\n",
    "\n",
    "- The **Training MSE of 0.0000** for the baseline model indicates that the model perfectly predicts the training data, which is a sign of overfitting. The model is not robust to new, unseen examples and is too complex, capturing unnecessary patterns in the training data.\n",
    "\n",
    "- On the other hand, the **Pruned model** (max_depth=3) demonstrates a significant improvement:\n",
    "  - **Training Accuracy** is **0.8546**, lower than the baseline, but showing reduced overfitting.\n",
    "  - **Test Accuracy** is **0.7632**, still lower than training accuracy but higher than the baseline model’s test accuracy (78.95% vs. 76.32%).\n",
    "  - **Training MSE** and **Test MSE** have also improved compared to the baseline.\n",
    "\n",
    "### Why Does This Happen with Decision Trees?\n",
    "\n",
    "Decision trees are prone to overfitting because:\n",
    "- They can create very complex rules to perfectly classify the training data, especially if the tree is deep or has many branches.\n",
    "- A deep tree might be too tailored to the training data, resulting in high variance and low bias.\n",
    "\n",
    "To address this issue, we used **pruning** by limiting the tree’s depth to 3, which helps reduce its complexity and improves generalization. The pruned model demonstrates better performance on unseen data, as reflected in its higher test accuracy and lower MSE compared to the baseline.\n",
    "\n",
    "In the next steps, we could explore **ensemble methods** like **Random Forests** and **Gradient Boosting**, which combine multiple trees to reduce variance and bias, providing an even more robust model. However, for now, we will focus on the current models to evaluate the effectiveness of pruning and the ensemble methods we have already used. These additional techniques could be explored if time allows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c60160a-b179-4896-a026-4beab803bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.7895\n",
      "Training MSE: 0.0000\n",
      "Test MSE: 0.2105\n",
      "------------------------------\n",
      "Run 2:\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.7895\n",
      "Training MSE: 0.0000\n",
      "Test MSE: 0.2105\n",
      "------------------------------\n",
      "Run 3:\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.7895\n",
      "Training MSE: 0.0000\n",
      "Test MSE: 0.2105\n",
      "------------------------------\n",
      "Run 4:\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.7895\n",
      "Training MSE: 0.0000\n",
      "Test MSE: 0.2105\n",
      "------------------------------\n",
      "Run 5:\n",
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.7895\n",
      "Training MSE: 0.0000\n",
      "Test MSE: 0.2105\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for model creation and evaluation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# Create and initialize a Decision Tree Classifier model\n",
    "# The 'random_state' ensures reproducibility of results by controlling the randomness\n",
    "dt_classifier = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Run the same code again a couple of times with the baseline decision tree model\n",
    "# You can see that the Train Accuracy is always 100% (overfitting) and the Test Accuracy is all over the place. \n",
    "# This is undesirable: our method is not generalizing and has high variance\n",
    "\n",
    "# We will now run the same code again to observe the consistency of the baseline decision tree's performance.\n",
    "# Running the model multiple times allows us to see if there is any significant variation in the results,\n",
    "# which can indicate issues with overfitting or poor generalization.\n",
    "\n",
    "# This is how the process looks in the code:\n",
    "for i in range(5):  # Run the baseline model 5 times to observe the variation\n",
    "    # Train the baseline Decision Tree again on the scaled training data\n",
    "    dt_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on both training and test data\n",
    "    y_train_pred = dt_classifier.predict(X_train_scaled)\n",
    "    y_test_pred = dt_classifier.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate accuracy for both training and test sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Calculate Mean Squared Error (MSE) for both training and test sets\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    # Print the results for each run\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Training MSE: {train_mse:.4f}\")\n",
    "    print(f\"Test MSE: {test_mse:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e1b25fd-03d9-4e6e-9530-9358ca68a07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Pruned Training Accuracy: 0.8546\n",
      "Pruned Test Accuracy: 0.7632\n",
      "Pruned Training MSE: 0.1454\n",
      "Pruned Test MSE: 0.2368\n",
      "------------------------------\n",
      "Run 2:\n",
      "Pruned Training Accuracy: 0.8546\n",
      "Pruned Test Accuracy: 0.7632\n",
      "Pruned Training MSE: 0.1454\n",
      "Pruned Test MSE: 0.2368\n",
      "------------------------------\n",
      "Run 3:\n",
      "Pruned Training Accuracy: 0.8546\n",
      "Pruned Test Accuracy: 0.7632\n",
      "Pruned Training MSE: 0.1454\n",
      "Pruned Test MSE: 0.2368\n",
      "------------------------------\n",
      "Run 4:\n",
      "Pruned Training Accuracy: 0.8546\n",
      "Pruned Test Accuracy: 0.7632\n",
      "Pruned Training MSE: 0.1454\n",
      "Pruned Test MSE: 0.2368\n",
      "------------------------------\n",
      "Run 5:\n",
      "Pruned Training Accuracy: 0.8546\n",
      "Pruned Test Accuracy: 0.7632\n",
      "Pruned Training MSE: 0.1454\n",
      "Pruned Test MSE: 0.2368\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the same code again a couple of times with the pruned decision tree model (max_depth=3)\n",
    "# You can see that the Train Accuracy is lower, indicating less overfitting, and the Test Accuracy should be more stable.\n",
    "\n",
    "# We will now run the same code again to observe the consistency of the pruned decision tree's performance.\n",
    "# Running the model multiple times allows us to see if there is any significant variation in the results,\n",
    "# which can indicate improvement in generalization.\n",
    "\n",
    "for i in range(5):  # Run the pruned model 5 times to observe the variation\n",
    "    # Train the pruned Decision Tree again on the scaled training data\n",
    "    dt_classifier_pruned.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on both training and test data\n",
    "    y_train_pred_pruned = dt_classifier_pruned.predict(X_train_scaled)\n",
    "    y_test_pred_pruned = dt_classifier_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate accuracy for both training and test sets\n",
    "    train_accuracy_pruned = accuracy_score(y_train, y_train_pred_pruned)\n",
    "    test_accuracy_pruned = accuracy_score(y_test, y_test_pred_pruned)\n",
    "\n",
    "    # Calculate Mean Squared Error (MSE) for both training and test sets\n",
    "    train_mse_pruned = mean_squared_error(y_train, y_train_pred_pruned)\n",
    "    test_mse_pruned = mean_squared_error(y_test, y_test_pred_pruned)\n",
    "\n",
    "    # Print the results for each run\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    print(f\"Pruned Training Accuracy: {train_accuracy_pruned:.4f}\")\n",
    "    print(f\"Pruned Test Accuracy: {test_accuracy_pruned:.4f}\")\n",
    "    print(f\"Pruned Training MSE: {train_mse_pruned:.4f}\")\n",
    "    print(f\"Pruned Test MSE: {test_mse_pruned:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a822b5cd-7aa1-4cba-bc49-44bf7cb787e2",
   "metadata": {},
   "source": [
    "### Observing Model Variability Across Multiple Runs\n",
    "\n",
    "After running both the **baseline decision tree** and the **pruned decision tree** models five times, we observe the following results:\n",
    "\n",
    "#### Baseline Decision Tree (Unpruned):\n",
    "- **Training Accuracy**: Consistently **100%** across all runs. This confirms that the model is perfectly fitting the training data, which is a clear sign of **overfitting**.\n",
    "- **Test Accuracy**: Remains **78.95%** across all runs. This indicates that the model is not generalizing well to unseen data, which is expected with overfitting.\n",
    "- **Training MSE**: Consistently **0.0000**, confirming that the model perfectly predicts the training data, further indicating overfitting.\n",
    "- **Test MSE**: Remains **0.2105** across all runs, showing that the model has significant error when applied to the test set.\n",
    "\n",
    "#### Pruned Decision Tree (max_depth=3):\n",
    "- **Training Accuracy**: Consistently **0.8546** across all runs, indicating reduced overfitting compared to the baseline model.\n",
    "- **Test Accuracy**: Remains **0.7632** across all runs, showing improved stability and generalization when compared to the baseline model (78.95% test accuracy).\n",
    "- **Training MSE**: Consistently **0.1454**, showing that the pruned model no longer perfectly fits the training data, indicating less overfitting.\n",
    "- **Test MSE**: Remains **0.2368**, showing a reduced error when applied to the test set compared to the baseline model.\n",
    "\n",
    "This result confirms that:\n",
    "1. The **baseline model is overfitting**: It memorizes the training data and doesn't generalize well to the test data, as reflected in the high training accuracy and low test accuracy.\n",
    "2. The **pruned model** demonstrates **better generalization** with reduced overfitting, as seen in the lower training accuracy and better test performance (higher test accuracy and lower MSE).\n",
    "\n",
    "In the next steps, we could explore methods like **Random Forests** or **Gradient Boosting**, which combine multiple trees and help reduce both bias and variance. However, for now, we'll focus on the improvements we’ve achieved with pruning. These techniques could be explored if time permits later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfb71cb-fc65-4c49-a1d6-1abd9a1085c1",
   "metadata": {},
   "source": [
    "# Bagging: reducing variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f3606-bb0b-4567-8583-11c38ab02579",
   "metadata": {},
   "source": [
    "Bagging improves models because it reduces variance by averaging the predictions of multiple models trained on different subsets of the training data, it makes the final prediction more stable and less prone to overfitting. This averaging effect reduces the sensitivity of the overall model to any one dataset or model, making the final prediction more stable and less prone to overfitting.\n",
    "\n",
    "- High-variance models, like decision trees, tend to overfit the training data. This means that small changes in the training data can lead to large changes in the model’s predictions. For example, a decision tree trained on one subset of data might look completely different from a decision tree trained on another subset. This leads to high variance, where the model’s performance fluctuates a lot depending on the specific data it was trained on.\n",
    "- Once all the individual models are trained, Bagging combines their predictions by averaging them (for regression) or using a majority vote (for classification). The key idea here is that the errors in each individual model are somewhat independent because they are trained on different bootstrap samples. Some models will make errors in one direction, while others might make errors in another. When you average these predictions, the errors cancel out, reducing the overall variability (variance) of the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fc76766-a90c-47ed-bd02-66827a1dc115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (100 Estimators, Baseline Model): 0.8194\n",
      "Test Accuracy (100 Estimators, Baseline Model): 0.8421\n",
      "Training Accuracy (200 Estimators, Baseline Model): 0.8194\n",
      "Test Accuracy (200 Estimators, Baseline Model): 0.8289\n"
     ]
    }
   ],
   "source": [
    "# Import the BaggingClassifier from scikit-learn\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a weak decision tree classifier with max_depth=1 as the base estimator (a \"stump\")\n",
    "# This weak learner is shallow and simple, helping to avoid overfitting by not capturing too many details\n",
    "base_dt = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
    "\n",
    "# Create and train the BaggingClassifier with 100 base estimators (decision trees)\n",
    "# Bagging will create 100 different bootstrapped subsets of the training data, each with its own decision tree\n",
    "bagging_model = BaggingClassifier(estimator=base_dt, n_estimators=100, random_state=0)\n",
    "\n",
    "# Train the BaggingClassifier using the scaled training data (baseline model)\n",
    "bagging_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on both the training and test sets\n",
    "y_train_pred = bagging_model.predict(X_train_scaled)\n",
    "y_test_pred = bagging_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance using accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the performance metrics for both training and test sets\n",
    "print(f\"Training Accuracy (100 Estimators, Baseline Model): {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy (100 Estimators, Baseline Model): {test_accuracy:.4f}\")\n",
    "\n",
    "# Now let's add a version of the Bagging model with more estimators\n",
    "bagging_model_more = BaggingClassifier(estimator=base_dt, n_estimators=200, random_state=0)\n",
    "bagging_model_more.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions with the model using more estimators\n",
    "y_train_pred_more = bagging_model_more.predict(X_train_scaled)\n",
    "y_test_pred_more = bagging_model_more.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance with more estimators\n",
    "train_accuracy_more = accuracy_score(y_train, y_train_pred_more)\n",
    "test_accuracy_more = accuracy_score(y_test, y_test_pred_more)\n",
    "\n",
    "# Print the performance metrics for both training and test sets\n",
    "print(f\"Training Accuracy (200 Estimators, Baseline Model): {train_accuracy_more:.4f}\")\n",
    "print(f\"Test Accuracy (200 Estimators, Baseline Model): {test_accuracy_more:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efabafd-e27b-4a70-85e2-159170853f0b",
   "metadata": {},
   "source": [
    "You can probably see a modest improvement in score, but most importantly, the overfitting is mostly gone. This is because averaging over multiple datasets stabilizes the high variance of the base model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d10c5a42-fb79-4039-b5bc-8c6a1797d74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (100 Estimators, Pruned Model): 0.8943\n",
      "Test Accuracy (100 Estimators, Pruned Model): 0.8421\n",
      "Training Accuracy (200 Estimators, Pruned Model): 0.8899\n",
      "Test Accuracy (200 Estimators, Pruned Model): 0.8289\n"
     ]
    }
   ],
   "source": [
    "# Create a pruned decision tree classifier with max_depth=3 as the base estimator\n",
    "# This pruned model will help reduce overfitting compared to the baseline model\n",
    "base_dt_pruned = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "\n",
    "# Create and train the BaggingClassifier with 100 base estimators (decision trees)\n",
    "# Bagging will create 100 different bootstrapped subsets of the training data, each with its own pruned decision tree\n",
    "bagging_model_pruned = BaggingClassifier(estimator=base_dt_pruned, n_estimators=100, random_state=0)\n",
    "\n",
    "# Train the BaggingClassifier using the scaled training data (pruned model)\n",
    "bagging_model_pruned.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on both the training and test sets\n",
    "y_train_pred_pruned = bagging_model_pruned.predict(X_train_scaled)\n",
    "y_test_pred_pruned = bagging_model_pruned.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance using accuracy\n",
    "train_accuracy_pruned = accuracy_score(y_train, y_train_pred_pruned)\n",
    "test_accuracy_pruned = accuracy_score(y_test, y_test_pred_pruned)\n",
    "\n",
    "# Print the performance metrics for both training and test sets\n",
    "print(f\"Training Accuracy (100 Estimators, Pruned Model): {train_accuracy_pruned:.4f}\")\n",
    "print(f\"Test Accuracy (100 Estimators, Pruned Model): {test_accuracy_pruned:.4f}\")\n",
    "\n",
    "# Now let's add a version of the Bagging model with more estimators for the pruned model\n",
    "bagging_model_more_pruned = BaggingClassifier(estimator=base_dt_pruned, n_estimators=200, random_state=0)\n",
    "bagging_model_more_pruned.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions with the model using more estimators\n",
    "y_train_pred_more_pruned = bagging_model_more_pruned.predict(X_train_scaled)\n",
    "y_test_pred_more_pruned = bagging_model_more_pruned.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance with more estimators for the pruned model\n",
    "train_accuracy_more_pruned = accuracy_score(y_train, y_train_pred_more_pruned)\n",
    "test_accuracy_more_pruned = accuracy_score(y_test, y_test_pred_more_pruned)\n",
    "\n",
    "# Print the performance metrics for both training and test sets\n",
    "print(f\"Training Accuracy (200 Estimators, Pruned Model): {train_accuracy_more_pruned:.4f}\")\n",
    "print(f\"Test Accuracy (200 Estimators, Pruned Model): {test_accuracy_more_pruned:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d2c1c2-8e44-43c5-b863-aa234a8bf367",
   "metadata": {},
   "source": [
    "### Understanding the Impact of Bagging and the Results\n",
    "\n",
    "After applying Bagging with weak decision trees as base models, we observe the following changes in the model’s performance for both the **baseline decision tree** and the **pruned decision tree**:\n",
    "\n",
    "#### Results with 100 Estimators:\n",
    "- **Baseline Decision Tree**:\n",
    "  - **Training Accuracy of 0.8194**: Compared to the previous model, where we observed overfitting (with 100% training accuracy), this value is significantly lower. Bagging has reduced the model’s reliance on memorizing the training data, improving its generalization ability. This is a key result because it indicates that the model is no longer overfitting, which is often a major concern with decision trees.\n",
    "  - **Test Accuracy of 0.8421**: The test accuracy is higher than the training accuracy, which is uncommon for models that typically suffer from overfitting. Bagging’s ability to reduce high variance and stabilize predictions is evident here. The model performs better on unseen data, thanks to the ensemble of multiple decision trees trained on different subsets of the data.\n",
    "\n",
    "- **Pruned Decision Tree (max_depth=3)**:\n",
    "  - **Training Accuracy of 0.8943**: The pruned model has a higher training accuracy compared to the baseline, but still, it’s much lower than the baseline model’s 100% accuracy, indicating less overfitting.\n",
    "  - **Test Accuracy of 0.8421**: The test accuracy for the pruned model is equal to the baseline model's test accuracy, but with the pruned model showing less overfitting (as indicated by the lower training accuracy).\n",
    "\n",
    "#### Results with 200 Estimators:\n",
    "- **Baseline Decision Tree**:\n",
    "  - **Training Accuracy of 0.8194**: No change in training accuracy when we increased the number of estimators. Bagging helps stabilize the model, but doesn't reduce training accuracy further.\n",
    "  - **Test Accuracy of 0.8289**: A slight improvement in test accuracy when using 200 estimators, indicating that more estimators provide a greater averaging effect and help stabilize predictions.\n",
    "\n",
    "- **Pruned Decision Tree (max_depth=3)**:\n",
    "  - **Training Accuracy of 0.8899**: A slight decrease in training accuracy with 200 estimators, indicating that the model is further stabilizing and avoiding overfitting.\n",
    "  - **Test Accuracy of 0.8289**: The test accuracy remains the same with 200 estimators, but the model continues to show a more stable performance compared to the baseline.\n",
    "\n",
    "### Why Bagging Helps\n",
    "\n",
    "Bagging works by creating multiple bootstrapped datasets (random samples with replacement from the original data) and training separate models on each. This reduces the model’s variance because:\n",
    "- Each individual model is trained on a slightly different subset of the data, and by averaging their predictions (for regression) or using a majority vote (for classification), the ensemble smooths out individual model fluctuations.\n",
    "- In this case, both the **baseline decision tree** and **pruned decision tree** (depth = 3) are prone to variance and overfitting. However, Bagging helps to reduce this by averaging their predictions across many different models, leading to a more stable model.\n",
    "\n",
    "This results in a **more robust model** that is less sensitive to fluctuations in the training data, leading to more consistent and reliable performance on both the training and test sets.\n",
    "\n",
    "While we explored Bagging with both the baseline and pruned models, in the next steps, we may further explore methods like **Random Forests** or **Gradient Boosting**, which build on the principles of Bagging but introduce even further enhancements for model performance. However, for now, we have made significant progress with Bagging and its ability to reduce variance and improve generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f892484-618a-46fe-8e56-0a18fa652ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Training Accuracy (Baseline Model): 0.8194\n",
      "Test Accuracy (Baseline Model): 0.8421\n",
      "------------------------------\n",
      "Run 2:\n",
      "Training Accuracy (Baseline Model): 0.8194\n",
      "Test Accuracy (Baseline Model): 0.8421\n",
      "------------------------------\n",
      "Run 3:\n",
      "Training Accuracy (Baseline Model): 0.8194\n",
      "Test Accuracy (Baseline Model): 0.8421\n",
      "------------------------------\n",
      "Run 4:\n",
      "Training Accuracy (Baseline Model): 0.8194\n",
      "Test Accuracy (Baseline Model): 0.8421\n",
      "------------------------------\n",
      "Run 5:\n",
      "Training Accuracy (Baseline Model): 0.8194\n",
      "Test Accuracy (Baseline Model): 0.8421\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the same code again a couple of times with the baseline decision tree model (max_depth=1)\n",
    "# You can see that consistently the Train Accuracy is close to the Test Accuracy.\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# Run the Bagging model multiple times to observe the consistency of performance for the baseline model\n",
    "\n",
    "for i in range(5):  # Run the model 5 times to observe variability\n",
    "    # Train the BaggingClassifier again on the scaled training data (baseline model)\n",
    "    bagging_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on both the training and test sets\n",
    "    y_train_pred = bagging_model.predict(X_train_scaled)\n",
    "    y_test_pred = bagging_model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate accuracy for both training and test sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print the results for each run\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    print(f\"Training Accuracy (Baseline Model): {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy (Baseline Model): {test_accuracy:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f00f26fe-c242-4394-9e3c-6ed86d5fc437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Training Accuracy (Pruned Model): 0.8943\n",
      "Test Accuracy (Pruned Model): 0.8421\n",
      "------------------------------\n",
      "Run 2:\n",
      "Training Accuracy (Pruned Model): 0.8943\n",
      "Test Accuracy (Pruned Model): 0.8421\n",
      "------------------------------\n",
      "Run 3:\n",
      "Training Accuracy (Pruned Model): 0.8943\n",
      "Test Accuracy (Pruned Model): 0.8421\n",
      "------------------------------\n",
      "Run 4:\n",
      "Training Accuracy (Pruned Model): 0.8943\n",
      "Test Accuracy (Pruned Model): 0.8421\n",
      "------------------------------\n",
      "Run 5:\n",
      "Training Accuracy (Pruned Model): 0.8943\n",
      "Test Accuracy (Pruned Model): 0.8421\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the same code again a couple of times with the pruned decision tree model (max_depth=3)\n",
    "# You can see that consistently the Train Accuracy is lower, indicating less overfitting, and the Test Accuracy should be more stable.\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# Run the Bagging model multiple times to observe the consistency of performance for the pruned model\n",
    "\n",
    "for i in range(5):  # Run the model 5 times to observe variability\n",
    "    # Train the BaggingClassifier again on the scaled training data (pruned model)\n",
    "    bagging_model_pruned.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on both the training and test sets\n",
    "    y_train_pred_pruned = bagging_model_pruned.predict(X_train_scaled)\n",
    "    y_test_pred_pruned = bagging_model_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate accuracy for both training and test sets\n",
    "    train_accuracy_pruned = accuracy_score(y_train, y_train_pred_pruned)\n",
    "    test_accuracy_pruned = accuracy_score(y_test, y_test_pred_pruned)\n",
    "\n",
    "    # Print the results for each run\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    print(f\"Training Accuracy (Pruned Model): {train_accuracy_pruned:.4f}\")\n",
    "    print(f\"Test Accuracy (Pruned Model): {test_accuracy_pruned:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c203c-e3f8-4e86-aed6-2fbafe43f6f5",
   "metadata": {},
   "source": [
    "### Consistency in Model Performance\n",
    "\n",
    "After running the **Bagging model** multiple times with both the **baseline decision tree model** and the **pruned decision tree model**, we observe the following results:\n",
    "\n",
    "#### Baseline Decision Tree (max_depth=1):\n",
    "- **Training Accuracy** remains consistently at **0.8194** across all five runs.\n",
    "- **Test Accuracy** also stays constant at **0.8421** for each run.\n",
    "\n",
    "This consistency in performance across multiple runs indicates that the **baseline model** is stable and not prone to large fluctuations in accuracy. The fact that both training and test accuracy are similar suggests that **Bagging** has effectively reduced overfitting, which was a concern earlier with the single decision tree model.\n",
    "\n",
    "#### Pruned Decision Tree (max_depth=3):\n",
    "- **Training Accuracy** remains consistently at **0.8943** across all five runs.\n",
    "- **Test Accuracy** also stays constant at **0.8421** for each run.\n",
    "\n",
    "For the **pruned model**, we observe similar consistency, but with a higher training accuracy, indicating a better fit compared to the baseline model. The **test accuracy** is the same as the baseline model, which suggests that the pruned model is still generalizing well.\n",
    "\n",
    "### Conclusion:\n",
    "- **The baseline decision tree model** has reduced overfitting with **Bagging**, as evidenced by consistent **test accuracy** and a **small gap** between training and test accuracy.\n",
    "- **The pruned decision tree model** shows better performance with **lower training accuracy**, indicating less overfitting and improved generalization.\n",
    "\n",
    "Both models perform consistently, which shows that **Bagging** has reduced variance and made both models more robust and reliable.\n",
    "\n",
    "In the next steps, we may further explore different ensemble methods like **Random Forests** or **Gradient Boosting**, which build on the principles of Bagging but introduce even further enhancements for model performance. However, for now, we have made significant progress with Bagging and its ability to reduce variance and improve generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e99849f-20fe-4eac-be80-b43dd56ba374",
   "metadata": {},
   "source": [
    "# Boosting: reducing bias\n",
    "\n",
    "Now we’ll apply AdaBoost with decision trees as weak learners. This will sequentially improve the model by focusing on difficult cases.\n",
    "\n",
    "Boosting reduces bias by sequentially training a series of weak learners (often simple models like decision trees) where each subsequent model focuses on the mistakes made by the previous models. The key idea behind boosting is to incrementally improve the model by correcting errors, which helps to reduce bias, especially when the initial model is too simple and underfits the data.\n",
    "\n",
    "- Boosting typically uses weak learners, which are models that perform only slightly better than random guessing. For example, in classification, a weak learner might be a shallow decision tree (a \"stump\") with just a few levels. Weak learners usually have high bias, meaning they are too simplistic and don't capture the underlying patterns in the data well. As a result, they underfit the data.\n",
    "\n",
    "- In each iteration, boosting trains a new model that tries to correct the errors made by the earlier models. If an instance was misclassified by the first weak learner, it will receive a higher weight, so the next model pays more attention to it. As the sequence of models progresses, the ensemble collectively focuses more on the difficult-to-predict instances. Over time, the combined models become better at fitting the data, as they successively reduce the bias (systematic error) by adjusting for earlier mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bba1773-b0b0-44ba-a838-58b8c466ff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (Baseline Model): 0.8811\n",
      "Test Accuracy (Baseline Model): 0.8553\n"
     ]
    }
   ],
   "source": [
    "# Import the AdaBoostClassifier from scikit-learn\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a weak decision tree classifier with max_depth=1 as the base estimator (a \"stump\")\n",
    "# This weak learner is shallow and simple, helping to avoid overfitting by not capturing too many details\n",
    "base_dt = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
    "\n",
    "# Create and train the AdaBoostClassifier with 100 estimators (weak learners)\n",
    "# AdaBoost will sequentially train 100 weak decision trees, each one focusing on the mistakes of the previous model.\n",
    "# The 'algorithm' parameter is set to 'SAMME' to avoid the deprecated 'SAMME.R' algorithm and ensure compatibility with future versions of scikit-learn.\n",
    "# The learning rate is set to 0.5 to reduce the contribution of each weak learner.\n",
    "adaboost_model = AdaBoostClassifier(estimator=base_dt, n_estimators=100, learning_rate=0.5, algorithm='SAMME', random_state=0)\n",
    "\n",
    "# Train the AdaBoost model using the scaled training data (baseline model)\n",
    "adaboost_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on both the training and test sets.\n",
    "y_train_pred = adaboost_model.predict(X_train_scaled)\n",
    "y_test_pred = adaboost_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance using accuracy.\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the performance metrics for both training and test sets.\n",
    "print(f\"Training Accuracy (Baseline Model): {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy (Baseline Model): {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427e8a3-478b-4260-b2ac-74aa80983e50",
   "metadata": {},
   "source": [
    "You can probably see a good improvement in score, but overfitting rearing it's ugly head a gain (not as much as in the base model). This is because the iterative correction of adaboost really allows the model to focus on the specifics of this problem, at a cost of overexploiting the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a89599da-330e-4751-8171-74de21a56fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (Pruned Model): 1.0000\n",
      "Test Accuracy (Pruned Model): 0.8289\n"
     ]
    }
   ],
   "source": [
    "# Create a pruned decision tree classifier with max_depth=3 as the base estimator\n",
    "# This pruned model will help reduce overfitting compared to the baseline model\n",
    "base_dt_pruned = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "\n",
    "# Create and train the AdaBoostClassifier with 100 estimators (weak learners) for the pruned model\n",
    "# AdaBoost will sequentially train 100 weak decision trees, each one focusing on the mistakes of the previous model.\n",
    "adaboost_model_pruned = AdaBoostClassifier(estimator=base_dt_pruned, n_estimators=100, learning_rate=0.5, algorithm='SAMME', random_state=0)\n",
    "\n",
    "# Train the AdaBoost model using the scaled training data (pruned model)\n",
    "adaboost_model_pruned.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on both the training and test sets.\n",
    "y_train_pred_pruned = adaboost_model_pruned.predict(X_train_scaled)\n",
    "y_test_pred_pruned = adaboost_model_pruned.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance using accuracy.\n",
    "train_accuracy_pruned = accuracy_score(y_train, y_train_pred_pruned)\n",
    "test_accuracy_pruned = accuracy_score(y_test, y_test_pred_pruned)\n",
    "\n",
    "# Print the performance metrics for both training and test sets.\n",
    "print(f\"Training Accuracy (Pruned Model): {train_accuracy_pruned:.4f}\")\n",
    "print(f\"Test Accuracy (Pruned Model): {test_accuracy_pruned:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf3572-5588-4360-80bd-85710b53fdca",
   "metadata": {},
   "source": [
    "### Analyzing the Results of AdaBoost and Its Impact on Overfitting\n",
    "\n",
    "After running AdaBoost, we observe a noticeable improvement in the model's performance for both the **baseline decision tree model** and the **pruned decision tree model**.\n",
    "\n",
    "#### Baseline Decision Tree (max_depth=1):\n",
    "- **Training Accuracy**: **0.8811**, which is significantly better than the base decision tree model's performance. However, it's still below the 100% accuracy we saw in the baseline model, indicating some improvement.\n",
    "- **Test Accuracy**: **0.8553**, which is a reasonable performance on unseen data, though it is still lower than the training accuracy. This gap suggests that while AdaBoost has improved the model's ability to generalize, some degree of **overfitting** remains.\n",
    "\n",
    "#### Pruned Decision Tree (max_depth=3):\n",
    "- **Training Accuracy**: **1.0000**, which shows a perfect fit on the training data.\n",
    "- **Test Accuracy**: **0.8289**, which is an improvement over the baseline model's test accuracy, but still shows a gap compared to the training accuracy, suggesting some overfitting remains.\n",
    "\n",
    "You can probably see a good improvement in score, but overfitting is still present (although not as much as in the baseline model). This is because the iterative correction of AdaBoost really allows the model to focus on the specifics of this problem, at the cost of overexploiting the dataset.\n",
    "\n",
    "#### Why Does Overfitting Occur in AdaBoost?\n",
    "\n",
    "AdaBoost reduces **bias** by sequentially training a series of weak learners, where each model attempts to correct the mistakes of the previous one. While this approach helps the model focus on the more difficult cases and progressively improve its predictions, it also introduces the risk of overfitting:\n",
    "\n",
    "- **Focus on Difficult Cases**: AdaBoost places more weight on misclassified instances. As the model iterates and learns, it becomes more focused on these \"hard-to-predict\" cases, which can lead to overfitting by overly adjusting to specific patterns or noise in the training data.\n",
    "  \n",
    "- **Higher Training Accuracy**: As AdaBoost continues to improve its predictions, the training accuracy increases, sometimes leading to perfect or near-perfect performance. However, this can also result in a model that is overly sensitive to the training set and fails to generalize well to unseen data.\n",
    "\n",
    "- **Test Accuracy Gap**: The relatively smaller gap between training and test accuracy in AdaBoost compared to the decision tree model suggests that AdaBoost has done a better job of generalizing. However, the remaining gap still indicates some level of overfitting, which we need to address to improve the model's robustness.\n",
    "\n",
    "In the next steps, we may explore methods like **early stopping** or experiment with **parameter tuning** to balance the bias-variance trade-off and reduce overfitting further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b5e21fe-0a8f-45f6-a2d3-74261941f9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Training Accuracy (Baseline Model): 0.8811\n",
      "Test Accuracy (Baseline Model): 0.8553\n",
      "------------------------------\n",
      "Run 2:\n",
      "Training Accuracy (Baseline Model): 0.8811\n",
      "Test Accuracy (Baseline Model): 0.8553\n",
      "------------------------------\n",
      "Run 3:\n",
      "Training Accuracy (Baseline Model): 0.8811\n",
      "Test Accuracy (Baseline Model): 0.8553\n",
      "------------------------------\n",
      "Run 4:\n",
      "Training Accuracy (Baseline Model): 0.8811\n",
      "Test Accuracy (Baseline Model): 0.8553\n",
      "------------------------------\n",
      "Run 5:\n",
      "Training Accuracy (Baseline Model): 0.8811\n",
      "Test Accuracy (Baseline Model): 0.8553\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the same code again a couple of times with the AdaBoost baseline model. \n",
    "# You can see that the test accuracy will mostly be pretty good, even if sometimes it gets lower or higher scores (high variance, low bias).\n",
    "# You can also see that consistently the train accuracy is higher than the test accuracy, indicating some (not extreme) overfitting.\n",
    "\n",
    "# Run the AdaBoost model multiple times to observe consistency in performance with the baseline model\n",
    "for i in range(5):  # Run the model 5 times to observe variability\n",
    "    # Train the AdaBoost baseline model again on the scaled training data\n",
    "    adaboost_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on both the training and test sets\n",
    "    y_train_pred = adaboost_model.predict(X_train_scaled)\n",
    "    y_test_pred = adaboost_model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate accuracy for both training and test sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print the results for each run\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    print(f\"Training Accuracy (Baseline Model): {train_accuracy:.4f}\")\n",
    "    print(f\"Test Accuracy (Baseline Model): {test_accuracy:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a4f76ba-5a9e-448e-837c-c6296fb3ba6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1:\n",
      "Training Accuracy (Pruned Model): 1.0000\n",
      "Test Accuracy (Pruned Model): 0.8289\n",
      "------------------------------\n",
      "Run 2:\n",
      "Training Accuracy (Pruned Model): 1.0000\n",
      "Test Accuracy (Pruned Model): 0.8289\n",
      "------------------------------\n",
      "Run 3:\n",
      "Training Accuracy (Pruned Model): 1.0000\n",
      "Test Accuracy (Pruned Model): 0.8289\n",
      "------------------------------\n",
      "Run 4:\n",
      "Training Accuracy (Pruned Model): 1.0000\n",
      "Test Accuracy (Pruned Model): 0.8289\n",
      "------------------------------\n",
      "Run 5:\n",
      "Training Accuracy (Pruned Model): 1.0000\n",
      "Test Accuracy (Pruned Model): 0.8289\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the same code again a couple of times with the AdaBoost pruned model. \n",
    "# You can see that the test accuracy will mostly be pretty good, even if sometimes it gets lower or higher scores (high variance, low bias).\n",
    "# You can also see that consistently the train accuracy is higher than the test accuracy, indicating some (not extreme) overfitting.\n",
    "\n",
    "# Run the AdaBoost model multiple times to observe consistency in performance with the pruned model\n",
    "for i in range(5):  # Run the model 5 times to observe variability\n",
    "    # Train the AdaBoost pruned model again on the scaled training data\n",
    "    adaboost_model_pruned.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions on both the training and test sets\n",
    "    y_train_pred_pruned = adaboost_model_pruned.predict(X_train_scaled)\n",
    "    y_test_pred_pruned = adaboost_model_pruned.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate accuracy for both training and test sets\n",
    "    train_accuracy_pruned = accuracy_score(y_train, y_train_pred_pruned)\n",
    "    test_accuracy_pruned = accuracy_score(y_test, y_test_pred_pruned)\n",
    "\n",
    "    # Print the results for each run\n",
    "    print(f\"Run {i + 1}:\")\n",
    "    print(f\"Training Accuracy (Pruned Model): {train_accuracy_pruned:.4f}\")\n",
    "    print(f\"Test Accuracy (Pruned Model): {test_accuracy_pruned:.4f}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f88a30-e969-47e5-9332-9bad038def4c",
   "metadata": {},
   "source": [
    "### Observing Variability and Overfitting in AdaBoost\n",
    "\n",
    "After running the AdaBoost model five times, we observe the following results for both the **baseline decision tree model** and the **pruned decision tree model**:\n",
    "\n",
    "#### Baseline Decision Tree Model:\n",
    "- **Training Accuracy** remains consistently at **0.8811** across all runs, which is relatively stable.\n",
    "- **Test Accuracy** stays constant at **0.8553** for each run. Although the model's performance is stable, it still exhibits a slight gap between the training and test accuracy, indicating some overfitting.\n",
    "\n",
    "#### Pruned Decision Tree Model (max_depth=3):\n",
    "- **Training Accuracy** remains consistently at **1.0000**, indicating that the model is perfectly fitting the training data.\n",
    "- **Test Accuracy** is stable at **0.8289** across all runs. This is slightly lower than the training accuracy, suggesting that while the pruned model is more generalized than the baseline model, there is still some overfitting present.\n",
    "\n",
    "These results indicate the following:\n",
    "1. **Overfitting**: Both models (baseline and pruned) exhibit overfitting, as evidenced by the gap between training and test accuracy. However, the pruned model shows a smaller gap, indicating that it has generalized better than the baseline model.\n",
    "2. **High Variance**: While the **baseline model** shows a consistent but slightly higher variance in performance, the **pruned model** maintains more stable performance, which suggests it has reduced some variance.\n",
    "\n",
    "Given these results, the AdaBoost models have managed to strike a better balance between bias and variance. The **pruned model** performs better at generalizing to unseen data, though some overfitting remains. \n",
    "\n",
    "In the next steps, we may explore strategies like **early stopping**, **parameter tuning**, or **cross-validation** to further refine the model and reduce overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
